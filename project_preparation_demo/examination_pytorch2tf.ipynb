{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook shows the results of the torch to tf translation function for 3 models:\n",
    "- a CNN with Dropout\n",
    "- the same CNN, but with intermediate layer output (to get better insights)\n",
    "- the same CNN, but without dropout\n",
    "\n",
    "Results:\n",
    "- the CNN with dropout has diverging outputs in torch and tf\n",
    "- without dropout, the outputs are the same"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "## get intermediate layers of pytorch model\n",
    "\n",
    "class LayerNet(Net):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x2 = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x1)), 2))\n",
    "        x3 = x2.view(-1, 320)\n",
    "        x4 = F.relu(self.fc1(x3))\n",
    "        x5 = F.dropout(x4, training=self.training)\n",
    "        x6 = self.fc2(x5)\n",
    "        return [x1, x2, x3, x4, x5, x6, F.log_softmax(x6, dim=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class NoDropoutNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NoDropoutNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "\n",
    "# Train this model with 60 epochs and after process every 300 batches log the train status\n",
    "args = parser.parse_args(['--epochs', '10', '--log-interval', '300'])\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "model = NoDropoutNet().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.342345\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.268953\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.295525\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.073861\n",
      "\n",
      "Test set: Average loss: 0.1234, Accuracy: 9636/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.166110\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.160232\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.063766\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.174566\n",
      "\n",
      "Test set: Average loss: 0.0768, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.013016\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.216341\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.111469\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.075249\n",
      "\n",
      "Test set: Average loss: 0.0611, Accuracy: 9802/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.192573\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.074138\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.061015\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.013557\n",
      "\n",
      "Test set: Average loss: 0.0553, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.020125\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.048200\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.013062\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.017415\n",
      "\n",
      "Test set: Average loss: 0.0549, Accuracy: 9822/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.020105\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.156984\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.001807\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.037305\n",
      "\n",
      "Test set: Average loss: 0.0496, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.108100\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.056432\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.141805\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.009236\n",
      "\n",
      "Test set: Average loss: 0.0470, Accuracy: 9850/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.008164\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.003295\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.076987\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.009666\n",
      "\n",
      "Test set: Average loss: 0.0392, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.031530\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.102339\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.049428\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.016132\n",
      "\n",
      "Test set: Average loss: 0.0398, Accuracy: 9879/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.007228\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.012325\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.075646\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.153365\n",
      "\n",
      "Test set: Average loss: 0.0370, Accuracy: 9884/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(args, model, device, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "torch.save(model.state_dict(), 'models/mnist_pytorch_24_06_22_no_dropout.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `__call__` contains input name(s) input.1 with unsupported characters which will be renamed to input_1 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mnist_tf.pb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mnist_tf.pb\\assets\n"
     ]
    }
   ],
   "source": [
    "from Main import translate\n",
    "tf_rep = translate(model, 'tf2', dummy_input=torch.randn([64, 1, 28, 28]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, input.1) at 0x1D7C866E100>})\n",
      "ConcreteFunction signature_wrapper(*, input.1)\n",
      "  Args:\n",
      "    input.1: float32 Tensor, shape=(64, 1, 28, 28)\n",
      "  Returns:\n",
      "    {'20': <1>, 'input': <2>, 'onnx::Gemm_16': <3>, 'onnx::Reshape_14': <4>, 'x4': <5>, 'x6': <6>}\n",
      "      <1>: float32 Tensor, shape=(64, 10)\n",
      "      <2>: float32 Tensor, shape=(64, 10, 12, 12)\n",
      "      <3>: float32 Tensor, shape=(64, 320)\n",
      "      <4>: float32 Tensor, shape=(64, 20, 4, 4)\n",
      "      <5>: float32 Tensor, shape=(64, 50)\n",
      "      <6>: float32 Tensor, shape=(64, 10)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14348/3569471657.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf_rep\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignatures\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf_rep\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignatures\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'serving_default'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mtf_layers\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf_rep\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtf_rep\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtf_rep\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: '_UserObject' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf_rep.signatures)\n",
    "print(tf_rep.signatures['serving_default'])\n",
    "tf_layers = tf.keras.Model(inputs=tf_rep.inputs, outputs=[tf_rep.layers[1].output]) + tf_rep.outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch-output: 3, tf-output: 3, label: 3\n",
      "torch-logits: tensor([-2.2453e+01, -1.8735e+01, -1.6440e+01, -1.4305e-06, -2.0227e+01,\n",
      "        -1.4445e+01, -2.3794e+01, -2.2566e+01, -1.4096e+01, -1.5670e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.2453272e+01 -1.8735226e+01 -1.6440443e+01 -1.6689287e-06\n",
      " -2.0227110e+01 -1.4444656e+01 -2.3794052e+01 -2.2565966e+01\n",
      " -1.4095890e+01 -1.5670005e+01]\n",
      "torch-output: 1, tf-output: 1, label: 1\n",
      "torch-logits: tensor([-1.2540e+01, -3.1590e-05, -1.2594e+01, -2.2395e+01, -1.0794e+01,\n",
      "        -1.9026e+01, -1.7555e+01, -1.2982e+01, -1.3298e+01, -1.5403e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.2540019e+01 -3.1709169e-05 -1.2594376e+01 -2.2394575e+01\n",
      " -1.0794280e+01 -1.9025883e+01 -1.7555111e+01 -1.2982286e+01\n",
      " -1.3298212e+01 -1.5403474e+01]\n",
      "torch-output: 3, tf-output: 3, label: 3\n",
      "torch-logits: tensor([-2.1479e+01, -1.7841e+01, -1.6366e+01, -2.7436e-03, -1.9129e+01,\n",
      "        -1.1551e+01, -3.0253e+01, -1.8565e+01, -9.9491e+00, -5.9211e+00],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.1478920e+01 -1.7840998e+01 -1.6365917e+01 -2.7436493e-03\n",
      " -1.9129492e+01 -1.1550504e+01 -3.0252674e+01 -1.8564812e+01\n",
      " -9.9491310e+00 -5.9210587e+00]\n",
      "torch-output: 0, tf-output: 0, label: 0\n",
      "torch-logits: tensor([-2.0861e-05, -2.6083e+01, -1.5475e+01, -1.9682e+01, -2.2162e+01,\n",
      "        -1.1420e+01, -1.5080e+01, -1.4001e+01, -1.4724e+01, -1.1711e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.0861407e-05 -2.6083357e+01 -1.5474738e+01 -1.9682379e+01\n",
      " -2.2162409e+01 -1.1419989e+01 -1.5079521e+01 -1.4001430e+01\n",
      " -1.4723573e+01 -1.1710629e+01]\n",
      "torch-output: 0, tf-output: 0, label: 0\n",
      "torch-logits: tensor([-4.4107e-06, -2.5356e+01, -2.0557e+01, -2.3383e+01, -2.2897e+01,\n",
      "        -1.7757e+01, -1.6026e+01, -1.2728e+01, -1.5444e+01, -1.3697e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-4.41073416e-06 -2.53561535e+01 -2.05572395e+01 -2.33830376e+01\n",
      " -2.28972549e+01 -1.77570152e+01 -1.60262604e+01 -1.27277222e+01\n",
      " -1.54435949e+01 -1.36966715e+01]\n",
      "torch-output: 5, tf-output: 5, label: 5\n",
      "torch-logits: tensor([-1.9159e+01, -2.4373e+01, -2.0310e+01, -1.2545e+01, -1.5430e+01,\n",
      "        -2.2254e-04, -1.8508e+01, -1.7647e+01, -1.2400e+01, -8.4467e+00],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.9159380e+01 -2.4372774e+01 -2.0310013e+01 -1.2544797e+01\n",
      " -1.5429989e+01 -2.2253898e-04 -1.8508204e+01 -1.7646627e+01\n",
      " -1.2399843e+01 -8.4467459e+00]\n",
      "torch-output: 3, tf-output: 3, label: 3\n",
      "torch-logits: tensor([-2.0802e+01, -2.5611e+01, -1.6504e+01, -1.7212e-04, -2.7447e+01,\n",
      "        -1.5681e+01, -3.1429e+01, -2.3067e+01, -1.7858e+01, -8.6685e+00],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.0801939e+01 -2.5610628e+01 -1.6504063e+01 -1.7224259e-04\n",
      " -2.7446507e+01 -1.5681192e+01 -3.1428852e+01 -2.3067099e+01\n",
      " -1.7857691e+01 -8.6684494e+00]\n",
      "torch-output: 7, tf-output: 7, label: 7\n",
      "torch-logits: tensor([-1.7753e+01, -1.1538e+01, -1.4725e+01, -1.6513e+01, -1.0168e+01,\n",
      "        -1.7263e+01, -2.8517e+01, -8.6542e-05, -1.6017e+01, -1.0184e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.7753216e+01 -1.1538097e+01 -1.4725310e+01 -1.6513281e+01\n",
      " -1.0168238e+01 -1.7262877e+01 -2.8516851e+01 -8.6542197e-05\n",
      " -1.6016657e+01 -1.0183982e+01]\n",
      "torch-output: 1, tf-output: 1, label: 1\n",
      "torch-logits: tensor([-1.4588e+01, -1.0514e-04, -1.4712e+01, -2.3129e+01, -9.3085e+00,\n",
      "        -1.8185e+01, -1.6958e+01, -1.1325e+01, -1.3331e+01, -1.7302e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.45876141e+01 -1.05256266e-04 -1.47119751e+01 -2.31294460e+01\n",
      " -9.30849457e+00 -1.81854420e+01 -1.69579468e+01 -1.13246040e+01\n",
      " -1.33311348e+01 -1.73016033e+01]\n",
      "torch-output: 2, tf-output: 2, label: 2\n",
      "torch-logits: tensor([-2.3880e+01, -1.5111e+01, -8.4638e-06, -1.5188e+01, -2.7091e+01,\n",
      "        -2.9064e+01, -3.1021e+01, -1.1840e+01, -1.4048e+01, -2.0051e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.3880058e+01 -1.5110553e+01 -8.5830325e-06 -1.5187682e+01\n",
      " -2.7091236e+01 -2.9063591e+01 -3.1021137e+01 -1.1840114e+01\n",
      " -1.4047755e+01 -2.0051277e+01]\n",
      "torch-output: 6, tf-output: 6, label: 6\n",
      "torch-logits: tensor([-1.0849e+01, -1.9023e+01, -1.3247e+01, -1.9313e+01, -1.5106e+01,\n",
      "        -1.2850e+01, -9.7347e-04, -2.5881e+01, -6.9602e+00, -1.7089e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.08485346e+01 -1.90231647e+01 -1.32465582e+01 -1.93131561e+01\n",
      " -1.51058235e+01 -1.28496103e+01 -9.73465911e-04 -2.58807068e+01\n",
      " -6.96022987e+00 -1.70890026e+01]\n",
      "torch-output: 0, tf-output: 0, label: 0\n",
      "torch-logits: tensor([-3.4267e-04, -1.2859e+01, -8.5911e+00, -1.3916e+01, -1.3366e+01,\n",
      "        -1.7077e+01, -9.2748e+00, -1.9674e+01, -9.7742e+00, -1.3739e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-3.4278716e-04 -1.2858717e+01 -8.5911007e+00 -1.3915956e+01\n",
      " -1.3365831e+01 -1.7076960e+01 -9.2747669e+00 -1.9673908e+01\n",
      " -9.7742195e+00 -1.3738833e+01]\n",
      "torch-output: 6, tf-output: 6, label: 6\n",
      "torch-logits: tensor([-13.6774, -22.1350, -17.5869, -21.7648, -23.9703,  -3.4674,  -0.0324,\n",
      "        -27.6405,  -7.3393, -20.2914], grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-13.677405   -22.13504    -17.58693    -21.764841   -23.97031\n",
      "  -3.4674175   -0.03236643 -27.640455    -7.339269   -20.291437  ]\n",
      "torch-output: 7, tf-output: 7, label: 7\n",
      "torch-logits: tensor([-1.1100e+01, -2.2972e+01, -2.0964e+01, -2.2256e+01, -1.0652e+01,\n",
      "        -9.0274e+00, -2.3787e+01, -6.2840e-03, -1.8785e+01, -5.0986e+00],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.1099765e+01 -2.2971649e+01 -2.0964468e+01 -2.2256262e+01\n",
      " -1.0651533e+01 -9.0274391e+00 -2.3787275e+01 -6.2840013e-03\n",
      " -1.8785244e+01 -5.0985770e+00]\n",
      "torch-output: 2, tf-output: 2, label: 2\n",
      "torch-logits: tensor([-1.4653e+01, -1.3259e+01, -2.3516e-03, -1.5165e+01, -1.0810e+01,\n",
      "        -2.0088e+01, -1.5995e+01, -1.9465e+01, -6.0640e+00, -1.3853e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.4652958e+01 -1.3259487e+01 -2.3516163e-03 -1.5165443e+01\n",
      " -1.0810034e+01 -2.0087671e+01 -1.5994563e+01 -1.9464638e+01\n",
      " -6.0639639e+00 -1.3853299e+01]\n",
      "torch-output: 8, tf-output: 8, label: 8\n",
      "torch-logits: tensor([-1.8147e+01, -2.3448e+01, -1.4558e+01, -1.0450e+01, -1.9318e+01,\n",
      "        -8.3223e+00, -1.5388e+01, -1.9706e+01, -2.7831e-04, -1.2100e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.8147242e+01 -2.3447527e+01 -1.4558061e+01 -1.0449751e+01\n",
      " -1.9317699e+01 -8.3222723e+00 -1.5387667e+01 -1.9705719e+01\n",
      " -2.7831495e-04 -1.2100313e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-1.9262e+01, -1.8530e+01, -1.4146e+01, -7.9781e+00, -7.2127e+00,\n",
      "        -1.2773e+01, -2.5035e+01, -1.2370e+01, -1.0794e+01, -1.1091e-03],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.9262297e+01 -1.8529594e+01 -1.4146265e+01 -7.9780564e+00\n",
      " -7.2127094e+00 -1.2773275e+01 -2.5035154e+01 -1.2370243e+01\n",
      " -1.0793792e+01 -1.1089849e-03]\n",
      "torch-output: 3, tf-output: 3, label: 3\n",
      "torch-logits: tensor([-2.0875e+01, -2.0971e+01, -1.9370e+01, -9.7751e-06, -2.5461e+01,\n",
      "        -1.3582e+01, -3.1906e+01, -2.5819e+01, -2.0539e+01, -1.1677e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.0874987e+01 -2.0971342e+01 -1.9369978e+01 -9.7751135e-06\n",
      " -2.5460848e+01 -1.3582233e+01 -3.1905962e+01 -2.5818575e+01\n",
      " -2.0538527e+01 -1.1677291e+01]\n",
      "torch-output: 8, tf-output: 8, label: 8\n",
      "torch-logits: tensor([-1.4321e+01, -1.0751e+01, -6.5749e+00, -1.3710e+01, -1.3833e+01,\n",
      "        -7.1702e+00, -5.5004e+00, -1.9983e+01, -6.2969e-03, -1.2526e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.4320568e+01 -1.0750545e+01 -6.5748849e+00 -1.3710005e+01\n",
      " -1.3832908e+01 -7.1701579e+00 -5.5003757e+00 -1.9982542e+01\n",
      " -6.2970323e-03 -1.2525881e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([ -7.9109, -16.8038, -12.0665, -10.6674,  -2.1454, -18.0199, -14.3799,\n",
      "        -12.9317,  -9.0877,  -0.1250], grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [ -7.9109073  -16.803783   -12.066532   -10.667442    -2.1453965\n",
      " -18.019886   -14.3799095  -12.931735    -9.087723    -0.12503448]\n",
      "torch-output: 4, tf-output: 4, label: 4\n",
      "torch-logits: tensor([-2.2755e+01, -8.5397e+00, -1.8447e+01, -2.3159e+01, -4.4479e-04,\n",
      "        -1.7288e+01, -2.2362e+01, -8.3442e+00, -1.1576e+01, -1.3116e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.27552471e+01 -8.53974247e+00 -1.84469471e+01 -2.31590023e+01\n",
      " -4.44909296e-04 -1.72882099e+01 -2.23616467e+01 -8.34423542e+00\n",
      " -1.15762224e+01 -1.31163845e+01]\n",
      "torch-output: 8, tf-output: 8, label: 8\n",
      "torch-logits: tensor([-1.2094e+01, -1.3595e+01, -6.8354e+00, -1.3982e+01, -1.6659e+01,\n",
      "        -1.8908e+01, -1.7943e+01, -1.9827e+01, -1.0959e-03, -1.1289e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.2093537e+01 -1.3595431e+01 -6.8353715e+00 -1.3982462e+01\n",
      " -1.6658531e+01 -1.8907572e+01 -1.7942820e+01 -1.9827290e+01\n",
      " -1.0958863e-03 -1.1289058e+01]\n",
      "torch-output: 2, tf-output: 2, label: 2\n",
      "torch-logits: tensor([-2.5485e+01, -1.5335e+01, -5.9604e-06, -1.6537e+01, -2.0765e+01,\n",
      "        -2.6268e+01, -2.9463e+01, -1.2194e+01, -1.4301e+01, -2.0011e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.5485250e+01 -1.5334728e+01 -5.9604467e-06 -1.6536907e+01\n",
      " -2.0764639e+01 -2.6267544e+01 -2.9462729e+01 -1.2194201e+01\n",
      " -1.4300740e+01 -2.0010689e+01]\n",
      "torch-output: 7, tf-output: 7, label: 7\n",
      "torch-logits: tensor([-1.8337e+01, -9.1880e+00, -1.2641e+01, -1.6282e+01, -5.0909e+00,\n",
      "        -2.3720e+01, -2.7822e+01, -6.2889e-03, -1.2779e+01, -1.1700e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.8337448e+01 -9.1880093e+00 -1.2640545e+01 -1.6281538e+01\n",
      " -5.0909085e+00 -2.3720362e+01 -2.7822023e+01 -6.2888586e-03\n",
      " -1.2779121e+01 -1.1699579e+01]\n",
      "torch-output: 0, tf-output: 0, label: 0\n",
      "torch-logits: tensor([  0.0000, -31.4482, -20.7817, -27.2713, -27.8480, -23.8568, -17.6333,\n",
      "        -22.0694, -19.8790, -16.7738], grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [  0.       -31.448217 -20.781725 -27.271313 -27.847958 -23.856825\n",
      " -17.63328  -22.06938  -19.879044 -16.773779]\n",
      "torch-output: 4, tf-output: 4, label: 4\n",
      "torch-logits: tensor([-2.7559e+01, -2.3063e+01, -2.1598e+01, -2.5072e+01, -8.3446e-07,\n",
      "        -1.9703e+01, -2.7270e+01, -1.9079e+01, -2.1370e+01, -1.3983e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.7559420e+01 -2.3063353e+01 -2.1597836e+01 -2.5072126e+01\n",
      " -8.3446469e-07 -1.9702637e+01 -2.7270428e+01 -1.9078817e+01\n",
      " -2.1369955e+01 -1.3983279e+01]\n",
      "torch-output: 6, tf-output: 6, label: 6\n",
      "torch-logits: tensor([-1.0108e+01, -5.5885e+00, -9.4112e+00, -1.2339e+01, -1.0246e+01,\n",
      "        -6.4204e+00, -5.9532e-03, -1.7316e+01, -7.8128e+00, -1.6946e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.0107688e+01 -5.5885434e+00 -9.4112225e+00 -1.2339369e+01\n",
      " -1.0245916e+01 -6.4203968e+00 -5.9531992e-03 -1.7316292e+01\n",
      " -7.8128176e+00 -1.6945555e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-2.2664e+01, -2.9713e+01, -1.9637e+01, -1.0779e+01, -1.3712e+01,\n",
      "        -1.8636e+01, -3.7943e+01, -1.3978e+01, -9.7708e+00, -7.9867e-05],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.2664242e+01 -2.9713074e+01 -1.9636702e+01 -1.0778919e+01\n",
      " -1.3711955e+01 -1.8636293e+01 -3.7942715e+01 -1.3978115e+01\n",
      " -9.7707863e+00 -7.9867037e-05]\n",
      "torch-output: 2, tf-output: 2, label: 2\n",
      "torch-logits: tensor([-2.7763e+01, -1.3215e+01, -2.5034e-06, -1.5959e+01, -2.0092e+01,\n",
      "        -2.7785e+01, -3.0832e+01, -1.4855e+01, -1.5453e+01, -1.8056e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.7762966e+01 -1.3214667e+01 -2.5033919e-06 -1.5958970e+01\n",
      " -2.0092188e+01 -2.7785246e+01 -3.0831751e+01 -1.4854556e+01\n",
      " -1.5453060e+01 -1.8055977e+01]\n",
      "torch-output: 2, tf-output: 2, label: 2\n",
      "torch-logits: tensor([-1.6054e+01, -1.5527e+01, -3.1590e-05, -1.1522e+01, -2.5337e+01,\n",
      "        -2.5338e+01, -2.3076e+01, -1.3930e+01, -1.0790e+01, -2.1722e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.6053576e+01 -1.5526964e+01 -3.1709169e-05 -1.1522214e+01\n",
      " -2.5337166e+01 -2.5338007e+01 -2.3075527e+01 -1.3930337e+01\n",
      " -1.0789815e+01 -2.1722263e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-1.2620e+01, -2.0497e+01, -1.6062e+01, -7.7695e+00, -5.7523e+00,\n",
      "        -1.4893e+01, -2.1013e+01, -4.6264e+00, -9.0185e+00, -1.3605e-02],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.26204586e+01 -2.04966412e+01 -1.60620308e+01 -7.76949835e+00\n",
      " -5.75227976e+00 -1.48927174e+01 -2.10132523e+01 -4.62635469e+00\n",
      " -9.01849937e+00 -1.36053655e-02]\n",
      "torch-output: 5, tf-output: 5, label: 5\n",
      "torch-logits: tensor([-2.2506e+01, -2.3220e+01, -2.1783e+01, -1.3209e+01, -1.8963e+01,\n",
      "        -2.6226e-05, -2.3337e+01, -1.8934e+01, -1.7983e+01, -1.0624e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.2506094e+01 -2.3219837e+01 -2.1782646e+01 -1.3208905e+01\n",
      " -1.8963318e+01 -2.6106494e-05 -2.3336689e+01 -1.8934208e+01\n",
      " -1.7982536e+01 -1.0623509e+01]\n",
      "torch-output: 1, tf-output: 1, label: 1\n",
      "torch-logits: tensor([-1.1650e+01, -3.9577e-05, -1.3593e+01, -1.9382e+01, -1.1337e+01,\n",
      "        -1.6221e+01, -1.3833e+01, -1.1700e+01, -1.1767e+01, -1.4384e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.1649629e+01 -3.9695904e-05 -1.3593345e+01 -1.9382204e+01\n",
      " -1.1337345e+01 -1.6220942e+01 -1.3832948e+01 -1.1699905e+01\n",
      " -1.1767436e+01 -1.4384058e+01]\n",
      "torch-output: 8, tf-output: 8, label: 8\n",
      "torch-logits: tensor([-1.3245e+01, -1.6129e+01, -9.2537e+00, -1.5852e+01, -1.3094e+01,\n",
      "        -1.1480e+01, -1.0431e+01, -1.3258e+01, -1.4566e-04, -1.2393e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.3244695e+01 -1.6128891e+01 -9.2536650e+00 -1.5851689e+01\n",
      " -1.3093728e+01 -1.1479574e+01 -1.0430593e+01 -1.3257941e+01\n",
      " -1.4554395e-04 -1.2392522e+01]\n",
      "torch-output: 0, tf-output: 0, label: 0\n",
      "torch-logits: tensor([-4.0531e-06, -2.0488e+01, -1.4230e+01, -2.0230e+01, -1.7939e+01,\n",
      "        -2.7350e+01, -1.2688e+01, -2.2580e+01, -1.5207e+01, -1.7862e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-3.9338988e-06 -2.0487900e+01 -1.4230345e+01 -2.0229761e+01\n",
      " -1.7938936e+01 -2.7350254e+01 -1.2687618e+01 -2.2579529e+01\n",
      " -1.5206992e+01 -1.7861576e+01]\n",
      "torch-output: 2, tf-output: 2, label: 2\n",
      "torch-logits: tensor([-2.0830e+01, -1.6373e+01, -3.6955e-06, -1.5824e+01, -2.4912e+01,\n",
      "        -2.6658e+01, -2.7276e+01, -1.3080e+01, -1.3532e+01, -2.2702e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.0829504e+01 -1.6373053e+01 -3.5762723e-06 -1.5824412e+01\n",
      " -2.4912100e+01 -2.6657837e+01 -2.7276121e+01 -1.3079629e+01\n",
      " -1.3531528e+01 -2.2702259e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-1.7930e+01, -1.3211e+01, -1.5469e+01, -1.4107e+01, -6.1925e+00,\n",
      "        -1.2976e+01, -2.2923e+01, -9.3958e+00, -7.1382e+00, -2.9313e-03],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.7929771e+01 -1.3211120e+01 -1.5468681e+01 -1.4106772e+01\n",
      " -6.1924930e+00 -1.2976200e+01 -2.2922590e+01 -9.3957615e+00\n",
      " -7.1381602e+00 -2.9314663e-03]\n",
      "torch-output: 1, tf-output: 1, label: 1\n",
      "torch-logits: tensor([-1.2950e+01, -1.5591e-04, -1.3398e+01, -1.4399e+01, -8.9728e+00,\n",
      "        -1.6211e+01, -1.5040e+01, -1.0795e+01, -1.2719e+01, -1.4123e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.2950483e+01 -1.5591360e-04 -1.3398343e+01 -1.4398882e+01\n",
      " -8.9728022e+00 -1.6210749e+01 -1.5040329e+01 -1.0795388e+01\n",
      " -1.2719328e+01 -1.4123157e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-2.1872e+01, -2.9340e+01, -2.0992e+01, -1.9663e+01, -1.5497e+01,\n",
      "        -2.2849e+01, -2.7986e+01, -2.4318e+01, -1.3465e+01, -1.6689e-06],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.18717403e+01 -2.93404617e+01 -2.09923706e+01 -1.96630650e+01\n",
      " -1.54970665e+01 -2.28486328e+01 -2.79857235e+01 -2.43183403e+01\n",
      " -1.34651012e+01 -1.66892869e-06]\n",
      "torch-output: 0, tf-output: 0, label: 0\n",
      "torch-logits: tensor([-1.1694e-04, -1.2210e+01, -1.0721e+01, -1.6223e+01, -1.2230e+01,\n",
      "        -1.6917e+01, -1.3584e+01, -1.5107e+01, -9.4592e+00, -1.2121e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.17056668e-04 -1.22096510e+01 -1.07214775e+01 -1.62225666e+01\n",
      " -1.22304363e+01 -1.69173527e+01 -1.35836086e+01 -1.51069164e+01\n",
      " -9.45917702e+00 -1.21210489e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-2.2172e+01, -2.5347e+01, -2.1343e+01, -9.8777e+00, -1.0529e+01,\n",
      "        -1.4421e+01, -2.8900e+01, -1.3363e+01, -1.1704e+01, -8.8449e-05],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.2171667e+01 -2.5346838e+01 -2.1343412e+01 -9.8776951e+00\n",
      " -1.0528550e+01 -1.4421105e+01 -2.8899544e+01 -1.3363218e+01\n",
      " -1.1704244e+01 -8.8449378e-05]\n",
      "torch-output: 1, tf-output: 1, label: 1\n",
      "torch-logits: tensor([-1.6093e+01, -9.7032e-05, -1.6664e+01, -1.8681e+01, -9.3392e+00,\n",
      "        -1.8270e+01, -1.7785e+01, -1.1750e+01, -1.4204e+01, -1.4788e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.6092710e+01 -9.7031654e-05 -1.6663635e+01 -1.8680559e+01\n",
      " -9.3392076e+00 -1.8270061e+01 -1.7784914e+01 -1.1750413e+01\n",
      " -1.4203538e+01 -1.4787819e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-2.4466e+01, -1.7373e+01, -1.7663e+01, -1.1558e+01, -7.4553e+00,\n",
      "        -2.2496e+01, -3.2321e+01, -1.1540e+01, -7.4288e+00, -1.1922e-03],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.4465578e+01 -1.7372732e+01 -1.7663160e+01 -1.1557514e+01\n",
      " -7.4553275e+00 -2.2496386e+01 -3.2321152e+01 -1.1540384e+01\n",
      " -7.4288430e+00 -1.1923355e-03]\n",
      "torch-output: 8, tf-output: 8, label: 8\n",
      "torch-logits: tensor([-2.3668e+01, -2.6470e+01, -1.6626e+01, -1.2675e+01, -2.6026e+01,\n",
      "        -2.3406e+01, -2.9201e+01, -2.0640e+01, -1.1086e-05, -1.1759e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.3667961e+01 -2.6470161e+01 -1.6625536e+01 -1.2675316e+01\n",
      " -2.6026127e+01 -2.3406019e+01 -2.9201000e+01 -2.0640388e+01\n",
      " -1.1086402e-05 -1.1758944e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-2.6889e+01, -2.2265e+01, -2.0465e+01, -1.4929e+01, -8.9607e+00,\n",
      "        -1.7196e+01, -3.7851e+01, -1.6363e+01, -1.6886e+01, -1.2886e-04],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.6889023e+01 -2.2264503e+01 -2.0465450e+01 -1.4928667e+01\n",
      " -8.9607048e+00 -1.7196272e+01 -3.7850830e+01 -1.6362658e+01\n",
      " -1.6885675e+01 -1.2885693e-04]\n",
      "torch-output: 3, tf-output: 3, label: 3\n",
      "torch-logits: tensor([-2.5791e+01, -1.7826e+01, -1.4678e+01, -1.1837e-04, -2.2912e+01,\n",
      "        -1.7914e+01, -3.6316e+01, -1.3937e+01, -1.4914e+01, -9.0556e+00],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.5791046e+01 -1.7825951e+01 -1.4677574e+01 -1.1836782e-04\n",
      " -2.2911644e+01 -1.7914387e+01 -3.6316277e+01 -1.3937019e+01\n",
      " -1.4914063e+01 -9.0556364e+00]\n",
      "torch-output: 6, tf-output: 6, label: 6\n",
      "torch-logits: tensor([-1.8579e+01, -2.7950e+01, -2.4658e+01, -2.4701e+01, -2.4359e+01,\n",
      "        -7.4823e+00, -5.7228e-04, -3.6478e+01, -1.1602e+01, -2.1937e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.8578793e+01 -2.7949614e+01 -2.4657526e+01 -2.4700552e+01\n",
      " -2.4358637e+01 -7.4823122e+00 -5.7227921e-04 -3.6478195e+01\n",
      " -1.1601764e+01 -2.1936977e+01]\n",
      "torch-output: 3, tf-output: 3, label: 3\n",
      "torch-logits: tensor([-9.6904e+00, -1.5896e+01, -8.5280e+00, -3.2465e-03, -1.3438e+01,\n",
      "        -1.1638e+01, -1.9169e+01, -8.1442e+00, -1.0717e+01, -5.9299e+00],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-9.6903887e+00 -1.5895938e+01 -8.5279770e+00 -3.2465153e-03\n",
      " -1.3437858e+01 -1.1637930e+01 -1.9169445e+01 -8.1442318e+00\n",
      " -1.0717181e+01 -5.9299369e+00]\n",
      "torch-output: 8, tf-output: 8, label: 8\n",
      "torch-logits: tensor([-10.7583,  -9.2242,  -4.1461,  -5.3301,  -7.5880,  -3.5680,  -9.7389,\n",
      "         -3.9142,  -0.0741,  -6.2694], grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-10.75833     -9.224229    -4.1461334   -5.3301272   -7.5880375\n",
      "  -3.567998    -9.738938    -3.9141574   -0.07409585  -6.2693806 ]\n",
      "torch-output: 7, tf-output: 7, label: 7\n",
      "torch-logits: tensor([-1.9942e+01, -1.5329e+01, -9.4213e+00, -1.2625e+01, -2.4152e+01,\n",
      "        -2.8211e+01, -3.6531e+01, -9.1668e-05, -2.0976e+01, -1.1846e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.9942276e+01 -1.5329118e+01 -9.4213419e+00 -1.2625433e+01\n",
      " -2.4151806e+01 -2.8211218e+01 -3.6530888e+01 -9.1667745e-05\n",
      " -2.0976112e+01 -1.1845776e+01]\n",
      "torch-output: 6, tf-output: 6, label: 6\n",
      "torch-logits: tensor([-1.3957e+01, -1.9633e+01, -2.0463e+01, -2.2900e+01, -1.6151e+01,\n",
      "        -1.2953e+01, -1.3471e-05, -2.7657e+01, -1.1497e+01, -2.1646e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.3956734e+01 -1.9632599e+01 -2.0462641e+01 -2.2900274e+01\n",
      " -1.6151178e+01 -1.2952726e+01 -1.3470559e-05 -2.7656721e+01\n",
      " -1.1497141e+01 -2.1646420e+01]\n",
      "torch-output: 7, tf-output: 7, label: 7\n",
      "torch-logits: tensor([-1.8178e+01, -1.9399e+01, -1.1216e+01, -1.7114e+01, -2.0804e+01,\n",
      "        -2.2397e+01, -3.8409e+01, -4.5537e-05, -2.4358e+01, -1.0348e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.8177700e+01 -1.9399237e+01 -1.1216043e+01 -1.7113729e+01\n",
      " -2.0804399e+01 -2.2397133e+01 -3.8409412e+01 -4.5536912e-05\n",
      " -2.4358231e+01 -1.0348028e+01]\n",
      "torch-output: 7, tf-output: 7, label: 7\n",
      "torch-logits: tensor([-1.7689e+01, -1.0882e+01, -8.4485e+00, -1.3635e+01, -1.3400e+01,\n",
      "        -1.9493e+01, -2.8505e+01, -6.8176e-04, -1.3655e+01, -7.7184e+00],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.7688856e+01 -1.0881746e+01 -8.4485044e+00 -1.3634674e+01\n",
      " -1.3400444e+01 -1.9492847e+01 -2.8504789e+01 -6.8176386e-04\n",
      " -1.3654833e+01 -7.7184443e+00]\n",
      "torch-output: 4, tf-output: 4, label: 4\n",
      "torch-logits: tensor([-2.1688e+01, -1.6893e+01, -1.9878e+01, -2.1499e+01, -1.5497e-06,\n",
      "        -2.0820e+01, -2.1121e+01, -1.3860e+01, -1.6766e+01, -1.4433e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-2.1687973e+01 -1.6892963e+01 -1.9877775e+01 -2.1499157e+01\n",
      " -1.5497195e-06 -2.0820127e+01 -2.1121359e+01 -1.3859658e+01\n",
      " -1.6766420e+01 -1.4433060e+01]\n",
      "torch-output: 2, tf-output: 2, label: 2\n",
      "torch-logits: tensor([-1.7047e+01, -1.0988e+01, -2.2650e-05, -1.2426e+01, -3.4144e+01,\n",
      "        -2.6370e+01, -2.8447e+01, -1.3675e+01, -1.4648e+01, -2.5891e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.7046631e+01 -1.0988476e+01 -2.2530301e-05 -1.2425678e+01\n",
      " -3.4143570e+01 -2.6369696e+01 -2.8447216e+01 -1.3674940e+01\n",
      " -1.4648471e+01 -2.5891243e+01]\n",
      "torch-output: 8, tf-output: 8, label: 8\n",
      "torch-logits: tensor([ -7.3908,  -5.6939,  -8.4791, -12.1244,  -9.3125, -10.4954,  -4.1774,\n",
      "        -17.4570,  -0.0199, -13.1586], grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [ -7.3908315   -5.693938    -8.4791155  -12.12444     -9.312472\n",
      " -10.495399    -4.177351   -17.457024    -0.01985123 -13.158617  ]\n",
      "torch-output: 7, tf-output: 7, label: 7\n",
      "torch-logits: tensor([-1.2298e+01, -1.3675e+01, -8.2445e+00, -8.6466e+00, -1.7391e+01,\n",
      "        -1.4657e+01, -2.9823e+01, -2.6586e-03, -1.6545e+01, -6.1146e+00],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.2298007e+01 -1.3675480e+01 -8.2444820e+00 -8.6466465e+00\n",
      " -1.7391275e+01 -1.4656570e+01 -2.9822559e+01 -2.6585257e-03\n",
      " -1.6545115e+01 -6.1145597e+00]\n",
      "torch-output: 5, tf-output: 5, label: 3\n",
      "torch-logits: tensor([-11.3121, -12.1233, -12.9624,  -0.9439, -15.3132,  -0.5262, -17.0251,\n",
      "         -9.9088,  -9.7547,  -3.9169], grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-11.312065  -12.12333   -12.962402   -0.943859  -15.313162   -0.5262011\n",
      " -17.025126   -9.908808   -9.754669   -3.9168653]\n",
      "torch-output: 2, tf-output: 2, label: 2\n",
      "torch-logits: tensor([-1.9273e+01, -1.6854e+01, -4.6610e-05, -1.4426e+01, -1.3584e+01,\n",
      "        -2.1375e+01, -1.9144e+01, -1.8096e+01, -1.0018e+01, -1.6894e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.92730827e+01 -1.68535728e+01 -4.64905424e-05 -1.44263077e+01\n",
      " -1.35835466e+01 -2.13748894e+01 -1.91435871e+01 -1.80959091e+01\n",
      " -1.00182905e+01 -1.68943920e+01]\n",
      "torch-output: 4, tf-output: 4, label: 4\n",
      "torch-logits: tensor([-1.3541e+01, -1.1815e+01, -1.2015e+01, -1.3013e+01, -3.7103e-04,\n",
      "        -1.6196e+01, -1.3525e+01, -8.1898e+00, -1.0119e+01, -1.0269e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.3540683e+01 -1.1815459e+01 -1.2015303e+01 -1.3013415e+01\n",
      " -3.7091051e-04 -1.6195927e+01 -1.3525267e+01 -8.1897745e+00\n",
      " -1.0118901e+01 -1.0268865e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-15.4797, -16.4948,  -9.3318,  -6.7271,  -9.1867, -14.6009, -29.0410,\n",
      "         -2.9032,  -6.2635,  -0.0599], grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-15.479743   -16.49481     -9.33179     -6.727108    -9.186698\n",
      " -14.600898   -29.041042    -2.9031885   -6.263493    -0.05990103]\n",
      "torch-output: 1, tf-output: 1, label: 1\n",
      "torch-logits: tensor([-1.2648e+01, -1.7415e-04, -1.6434e+01, -2.2060e+01, -9.0488e+00,\n",
      "        -1.7555e+01, -1.6954e+01, -1.0515e+01, -1.0559e+01, -1.6241e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.26482115e+01 -1.74149609e-04 -1.64341564e+01 -2.20601177e+01\n",
      " -9.04878139e+00 -1.75550880e+01 -1.69538994e+01 -1.05149784e+01\n",
      " -1.05587549e+01 -1.62407837e+01]\n",
      "torch-output: 4, tf-output: 4, label: 4\n",
      "torch-logits: tensor([-1.8497e+01, -1.6262e+01, -1.5350e+01, -1.4404e+01, -2.8610e-06,\n",
      "        -1.7510e+01, -1.8137e+01, -1.3845e+01, -1.4540e+01, -1.4481e+01],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.8496737e+01 -1.6261978e+01 -1.5350020e+01 -1.4403605e+01\n",
      " -2.8610189e-06 -1.7510447e+01 -1.8137041e+01 -1.3844619e+01\n",
      " -1.4540120e+01 -1.4480559e+01]\n",
      "torch-output: 9, tf-output: 9, label: 9\n",
      "torch-logits: tensor([-1.8292e+01, -1.9404e+01, -1.8078e+01, -1.1837e+01, -6.2084e+00,\n",
      "        -1.3735e+01, -2.9281e+01, -1.3405e+01, -1.4806e+01, -2.0247e-03],\n",
      "       grad_fn=<UnbindBackward0>)\n",
      "tf-logits: [-1.8291733e+01 -1.9404408e+01 -1.8077965e+01 -1.1836627e+01\n",
      " -6.2083960e+00 -1.3734525e+01 -2.9281303e+01 -1.3404829e+01\n",
      " -1.4805525e+01 -2.0247451e-03]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "features, labels = next(iter(train_loader))\n",
    "tf_logits_full = tf_rep(**{'input.1':features})\n",
    "tf_logits = tf_logits_full['20']\n",
    "#tf_input_layer = tf_logits_full['input']\n",
    "tf_output = np.argmax(tf_logits, axis=1)\n",
    "torch_logits_full = model(features)\n",
    "torch_logits = torch_logits_full\n",
    "#torch_input_layer = torch_logits_full[0]\n",
    "torch_output = torch.argmax(torch_logits, dim=1)\n",
    "for torch_l, torch_o, tf_l, tf_o, y in zip(torch_logits, torch_output, tf_logits, tf_output, labels.tolist()):\n",
    "        print(f'torch-output: {torch_o}, tf-output: {tf_o}, label: {y}')\n",
    "        print(f'torch-logits: {torch_l}')\n",
    "        print(f'tf-logits: {tf_l}')\n",
    "        # print(f'torch-input-layer: {torch_i[0]}')\n",
    "        # print(f'tf-input-layer: {tf_i[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}